# Netron Dev Note

Ignoring python web server, directly use `Electron` app

## TODO

- [ ] src is too messy now; move everything into its own folder. Files that were possibly affected:
	- [x] launch.json
	- [??] electron-builder.yml
	- [x] package.json
	- [x] README.md
	- [??] setup.py
	- [x] tf-metadata.json
	- [x] view-browser.html
	- [??] view-browser.js
		- might be a problem here `script.setAttribute('src', this._url(id + '.js'));`
	- [x] view-electron.html
	- [??] view-electron.js
		- same problem as above
	- [??] view.js
	- [??] test/app.js
		- same
	- [x] index.html
	- [??] update
	- [x] caffe-update
	- [x] caffe2-metadata.py
	- [x] cntk-update
	- [x] keras-metadata.py
	- [x] mxnet-metadata.py
	- [x] mxnet-update
	- [x] onnx-metadata.py
	- [x] onnx-update
	- [x] pytorch-metadata.py
	- [x] pytorch-update
	- [x] sklearn-metadata.py
	- [x] tf-metadata.py
	- [x] tf-update
	- [x] tflite-update

- [ ] src/image

- [ ] move `view-*` to src/view

## Code reading
- [ ] {ROOT}/app.js
	- [x] class Application
		- start the app; open/load files; set up top menu etc
		- create one instance per class (of class below)
	- [x] class View
		- controls basic View settings (open/restorm/execute/update/...) etc
	- [ ] class ViewCollection
		- ???
	- [ ] class ConfigurationService
		- load/save user data etc
	- [x] class MenuService
	- create an Instance of Application

- Assume we only support .pb files now
	- Models involve .pb:
		- { name: 'ONNX Model', extensions: [ 'onnx', 'pb', 'pbtxt' ] },
		- { name: 'Caffe2 Model', extensions: [ 'pb', 'pbtxt' ] },
		- { name: 'TensorFlow Graph', extensions: [ 'pb', 'meta', 'pbtxt' ] },
		- { name: 'TensorFlow Saved Model', extensions: [ 'pb', 'pbtxt' ] },

## Dev Note
1. Use `console.log()` will output to nodejs listener window
2. A variable in JavaScript can contain any data. A variable can at one moment be a string and later receive a numeric value!!!!!!!!!!!!!!
3. `var` vs `let`
let allows you to declare variables that are limited in scope to the block, statement, or expression on which it is used. This is unlike the var keyword, which defines a variable globally, or locally to an entire function regardless of block scope.


1. -proto.js is generated by metadata/-update!
2. -metadata.json is also generated by metadata/-update !!! 



add any extra npm module to package-lock.json
```
npm i ajv
npm install python-shell
```
looks like it's auto update package.json dependencies


## Bug
### Origin Bug
After export, upper left buttons disappear

## Random

`showNodeProperties`
`node` from `nodes`, `nodes` from `graph.nodes`

`renderGraph`

`updateGraph`

`this._sidebar.open()` auto converts the title string to upper cases

`tf-operator-json.py` -> `tf-metadata.py` (he manually wrote the file
`input_file = '../../third_party/tensorflow/tensorflow/core/ops/ops.pbtxt';` ==tf-metadata.py==> tf-metada.json

to add attributes, i need to modify the most bottom level text file

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/ops.pbtxt

I plan to add to every `op` that contains attr strides, or just add to every `op`??? and decide whether allow to add that to view on .js level
```
attr {
	name: "hardware_target"
	type: "string"
	allowed_values {
		list {
			s: "APEX"
			s: "CPU"
			s: "HW-Target-1"
			s: "HW-Target-2"
		}
	}
}

attr {
	name: "quantization_type"
	type: "string"
	allowed_values {
		list {
			s: "Floating-point"
			s: "Fixed-point"
			s: "quant-type-1"
			s: "quant-type-2"
		}
	}
}
```

This just changed ops (aka tensorflow operations), but it doesn't change any graph's node.
====
Maybe load .pb file and modify (add custom attributes) then save it again?

[TensorFlow question websites](https://www.reddit.com/r/tensorflow/comments/7jyshi/where_can_i_go_to_ask_really_stupid_tensorflow/)

[node_def.proto](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/node_def.proto)
[attr_value.proto](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/attr_value.proto)



https://blog.metaflow.fr/tensorflow-saving-restoring-and-mixing-multiple-models-c4c94d5d7125
```
I don’t want to go into details but think about it (protocol buffers) as a faster JSON format that you can compress when you need to save space/bandwidth for storage/transfer. To recapitulate, you can use Protobufs as:

- An uncompressed, human-friendly, text format with the extension .pbtxt
- A compressed, machine friendly, binary format with the extension .pb or no extension at all

Neat trick: All operations dealing with Protobufs in TensorFlow have this “_def” suffix that indicates “protocol buffer definition”. For example, to load the Protobufs of a saved graph, you can use the function: tf.import_graph_def. And to get the current graph as a Protobufs, you can use: Graph.as_graph_def().
```



A Graph contains a set of tf.Operation objects, which represent units of computation; and tf.Tensor objects, which represent the units of data that flow between operations.

A default Graph is always registered, and accessible by calling tf.get_default_graph. To add an operation to the default graph, simply call one of the functions that defines a new Operation:



An `Operation` is a node in a TensorFlow `Graph` that takes zero or
  more `Tensor` objects as input, and produces zero or more `Tensor`
  objects as output. Objects of type `Operation` are created by
  calling a Python op constructor (such as
  @{tf.matmul})
  or @{tf.Graph.create_op}.













```
as a 1st step experiment, can we dump the network structure into text format?

Try following python script on protobuf model, it will genated txt based dot network description

https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/tools/quantization/graph_to_dot.py

Is it possible to add a export function to netron to export same txt based network description?

 Once above experiment is successful, we can add json annotation export functionality. we still need to define what format in json annotation as part of high level design process.

 

Also as Brady mentioned, we dont need to modify protobuf, but we want to be able to 

add network annotation in GUI and export to json annotation file.

 

One simple example is in GUI, if one network has 10 layers, we can specify first 5 layers belongs to subgraph_1 and  remaining 5 layers to subgraph_2, then once we export those annotations, the final json would be something like following:

  
"ainet":{
   "sub_graph1: {
      "layer1": {},
       "layer2": {},
       "layer3": {},
       "layer4": {},
       "layer5": {},
    },
     "sub_graph2: {
      "layer6": {},
       "layer7": {},
       "layer8": {},
       "layer9": {},
       "layer10": {},
    },
 }
 
```